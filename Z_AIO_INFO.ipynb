{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98601732-c4e8-4575-8692-b5cf7110630a",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# IMPLEMENTATION DETAILS\n",
    "### TYPE - ML Classification\n",
    "### PROJECT - \"RED WINE QUALITY\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70800d69-01c8-4798-bd5f-ad32bd27bbfd",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# A. DATA ASSESSMENT PROCESS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4ebe03-3f70-4633-8f84-e3639d47e477",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## 1. DATASET SUMMARY\n",
    "### - It is a 'Red Wine' dataset that provides the information about various features to predict the quality type.\n",
    "### - There are 1599 observations and 12 features in the dataset.\n",
    "### - Total 'float' type features are 11, 'integer' type features are 1.\n",
    "#### - float type : 'fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol'.\n",
    "#### - int type : 'quality'.\n",
    "### - For machine learning applications 'quality' feature is the target variable (dependent) and the other 11 features are input (independent)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ff828e-ea31-4b8a-8919-4ba6a03dd2a8",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## 2. FEATURE DESCRIPTIONS\n",
    "### Table - 'red_wine' using 'winequality_red.csv'\n",
    "### * Independent Features\n",
    "#### - **'fixed acidity'** {float} : ***Acids that are always present***.\n",
    "#### - **'volatile acidity'** {float} : ***Gaseous acids with high values leave an unpleasant vinegar taste.***\n",
    "#### - **'citric acid'** {float} : ***A preservative added in small quantity to increase acidity and for freshness and flavor.***\n",
    "#### - **'residual sugar'** {float} : ***The amount of sugar left after fermentation.***\n",
    "#### - **'chlorides'** {float} : ***The amount of salt present in the wine.***\n",
    "#### - **'free sulfur dioxide'** {float} : ***It prevents growth of microbes and oxidation of the wine.***\n",
    "#### - **'total sulfur dioxide'** {float} : ***The amount of free and bound forms of SO2.***\n",
    "#### - **'density'** {float} : ***Higher density wines are sweet in taste.***\n",
    "#### - **'pH'** {float} : ***Acidity level of the wine.***\n",
    "#### - **'sulphates'** {float} : ***An additive to wine which is antimicrobial and antioxidant.***\n",
    "#### - **'alcohol'** {float} : ***The amount of alcohol present in wine.***\n",
    "\n",
    "### * Dependent Feature\n",
    "#### - **'quality'** {int} : ***It indicates the quality of the wine***.\n",
    "##### This feature is the target variable for Machine Learning Based Classification Type Problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ce43fc-3603-4a1b-83b0-b4cc50ece8de",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## 3. DATA ISSUES\n",
    "### Table - red_wine\n",
    "#### 1. * Dirty Data (Low quality)\n",
    "##### A. Completeness\n",
    "##### - No incompleteness issue\n",
    "##### B. Validity\n",
    "##### - Total duplicate observations - 240.\n",
    "##### C. Accuracy\n",
    "##### - No inaccuracy issue\n",
    "##### D. Consistency\n",
    "##### - No inconsistency issue\n",
    "\n",
    "#### 2. * Messy Data (Untidy / Structural)\n",
    "##### - No messy data issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735a986c-563b-4662-a8d3-b167c39fb847",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# B. PRE-PROCESSING / DATA CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a742847-5f7b-44eb-9451-6095f051be0d",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## 1. BASIC DATA PRE-PROCESSING APPLIED\n",
    "### - Dropping duplicated obervations : 240\n",
    "### - Resetting the index of the dataframe to discard the missing indices.\n",
    "### - Splitting the pre-processed dataframe into Train, Validation, and Test datasets.\n",
    "### - Finally saving the Train, Validation, and Test datasets into CSV and PKL files for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23215fe-7462-42b1-a889-44c25b1a2333",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## 2. RESULTS OF BASIC DATA PRE-PROCESSING\n",
    "### - Dropped 240 duplicates observation, ***successful***.\n",
    "### - Index reset, ***successful***."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0372481b-34ba-4921-a598-4ca975779fc8",
   "metadata": {},
   "source": [
    "## 3. SAVING RESULTS TO CSV AND PKL FILES \n",
    "### - Splitting the pre-processed dataframe into Train, Validation, and Test datasets, ***successful***.\n",
    "### - Pre-Processed Train, Validation, and Test datasets stored in CSV and PKL files, ***successful***.\n",
    "#### - Train (wine_quality_train_pp.csv, wine_quality_train_pp.pkl)\n",
    "#### - Validation (wine_quality_valid_pp.csv, wine_quality_valid_pp.pkl)\n",
    "#### - Test (wine_quality_test_pp.csv, wine_quality_test_pp.pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0987f9-97aa-4972-8830-8c6f95b8d496",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# C. EDA CONCLUSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef27a6e-1176-46b2-9322-00e5c2287e92",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## a. Uni-Variate EDA conclusions\n",
    "\n",
    "### . Numerical Features\n",
    "#### - There are no missing values in any of the features.\n",
    "#### - More features have moderate to high skewed distribution i.e., features are not Normally Distributed.\n",
    "#### - Outliers vary in the range of (0.08-9.23) % for the features.\n",
    "\n",
    "### . Categorical Features \n",
    "#### - 'quality' is considered as a categorical type feature, instead of integer type.\n",
    "#### - 'quality' has label '5' with mode value = 491, and no missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f70cd9-3344-41e2-a8f9-290653a39179",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## b. Bi/Multi Variate EDA conclusions\n",
    "\n",
    "### . Numerical-Numerical\n",
    "#### -> 'quality' vs others\n",
    "##### - High : positive(), negative()\n",
    "##### - Moderate : positive(alcohol), negative(volatile acidity)\n",
    "##### - Low : positive(fixed acidity, citric acid, sulphates), negative(chlorides, total sulfur dioxide, density)\n",
    "##### - Very Low : positive(residual sugar), negative(free sulfur dioxide, pH)\n",
    "\n",
    "### . Categorical-Numerical\n",
    "#### -> 'quality' vs others\n",
    "##### - Outliers for different labels of quality.\n",
    "##### - Features contributing for high quality wine are alcohol, sulphates, fixed acidity, citric acid, residual sugar.\n",
    "##### - Features contributing for low quality wine are pH, chlorides, volatile acidity, total sulfur dioxide, density, free sulfur dioxide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4abc2e-23e0-41b0-a467-9105bdc1307e",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# D. FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaeed74-8fdb-4753-a532-c70f67e67806",
   "metadata": {},
   "source": [
    "## A. Observations\n",
    "#### 1. Target feature \"quality\" should be remapped as \"low\" for (3,4,5) and \"high\" for (6,7,8) labels.\n",
    "#### 2. \"SMOTE\" oversampling technique should to be applied to balance the class distribution.\n",
    "#### 3. Outliers are present in the range of [0-10] %. Should apply outliers handling techniques.\n",
    "#### 4. Data in numerical columns is skewed. Should treat feature with transformation operations.\n",
    "#### 5. Check if the features are multi-collinear or not.\n",
    "#### 6. Feature scaling techniques must be applied to bring the dataset in the suitable form for model building.\n",
    "#### 7. Feature selection techniques must be applied to have better performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c174d8c2-889a-4349-afe3-b5df23b00578",
   "metadata": {},
   "source": [
    "## B. Steps of Feature Engineering\n",
    "#### 1. Binarization of target feature 'quality' as 'Low' and 'High' for Train, Validation and Test dataset.\n",
    "#### 2. Applying the SMOTE oversampling technique on the Train dataset to balance the distribution of target feature 'quality'.\n",
    "\n",
    "#### 3. Oultier Detection and Handling using Capping Technique\n",
    "##### - 'fixed acidity', 'volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol'\n",
    "\n",
    "##### - Detect and handle outliers in numerical features of Train dataset only.\n",
    "\n",
    "#### 4. Feature Transformation (to be applied in pipeline)\n",
    "#### - Checking various features transformations: (Log), (Square), (Reciprocal), (Square Root), (Exponential), (Yeo-Johnson)\n",
    "##### - 'fixed acidity', 'volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol'\n",
    "\n",
    "##### - 'Yeo-Johnson' Transformation is performing better in comparison to other transformations.\n",
    "##### - Apply 'Yeo-Johnson' on numerical features of Train, Validation, and Test dataset.\n",
    "\n",
    "#### 5. Multi-Colllinearity Check using VIF \n",
    "##### - VIF of other features is too high except 4 features ('total sulfur dioxide', 'free sulfur dioxide', 'volatile acidity', 'citric acid').\n",
    "##### - High multi-collinearity exists between the other features.\n",
    "\n",
    "#### 6. Scaling (StandardScaler / MinMaxScaler) (to be applied in pipeline)\n",
    "\n",
    "##### - 'fixed acidity', 'volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol'\n",
    "##### - Apply 'StandardScaler' on numerical features of Train, Validation, and Test dataset to reduce the skew.\n",
    "\n",
    "#### 7. Feature Selection Techniques (to be applied in pipeline)\n",
    "##### - Apply SelectKBest with mutual_info_classif to select the top k features for Model Building using estimators.\n",
    "##### - Treat Train, Validation, and Test dataset with feature selection strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057a1043-901b-45c1-899e-988aa094512b",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# E. ML MODELS IMPLEMENTATIONS & RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49986fc-2785-4a31-a8c0-7d27c4858473",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## A. Simple Model (using pipeline)\n",
    "\n",
    "#### 1. Feature Engineering. (Target mapping and abeling)\n",
    "#### 2. No Hyper Parameters tuning used.\n",
    "\n",
    "#### 3. Dataset Size:\n",
    "- Train Dataset size : (1159,12)\n",
    "- Validation Dataset size : (100,12)\n",
    "\n",
    "#### 4. Model: LogisticRegression(random_state=46)\n",
    "- Train Acc: 75.0647 %, Validation Acc: 70.0 %\n",
    "- CV Score (k=10): 74.9843 %, StratifiedKFold\n",
    "- ***Acceptable performance for Train and Validation sets.***\n",
    "- ***Performing well on both datasets.***\n",
    "\n",
    "#### 5. Model: RandomForestClassifier(random_state=46)\n",
    "- Train Acc: 100.0 %, Validation Acc: 69.0 % \n",
    "- CV Score (k=10): 75.7534 %, StratifiedKFold\n",
    "- ***Model has shown overfitting behavior.***\n",
    "- ***Not performing well on Validation set.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793ff79f-2279-4555-bb5b-9de0c31a0de4",
   "metadata": {},
   "source": [
    "## B. Feature Engineered Model (using pipeline)\n",
    "\n",
    "#### 1. FE: target labeling, data balancing (SMOTE), outlier handling (IQR and Capping), numerical feature transformation (Yeo-Johnson), scaling (StandardScaler), feature selection{SelectKBest, mutual_info_classif, k='all').\n",
    "#### 2. Some Hyper Parameter tuned.\n",
    "\n",
    "#### 3. Dataset Size:\n",
    "- Final Train Dataset size : (1230,12)\n",
    "- Validation Dataset size : (100,12)\n",
    "\n",
    "#### 4. Model: LogisticRegression(C=0.5, random_state=46)\n",
    "- Train ACC: 76.1789 %  %, Validation Acc: 74.0 %\n",
    "- CV Score (k=10): 76.1789 %, StratifiedKFold\n",
    "- ***Acceptable performance for Train and Validation sets.***\n",
    "- ***Performing well on both datasets.***\n",
    "\n",
    "#### 5. Model: RandomForestClassifier(n_estimators=200, max_depth=3, random_state=46)\n",
    "- Train ACC: 77.3984 %, Validation Acc: 76.0 %\n",
    "- CV Score (k=10): 76.2602 %, StratifiedKFold\n",
    "- ***Acceptable performance for Train and Validation sets.***\n",
    "- ***Performing well on Validation set.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f01e77f-f525-4e4d-aa72-4eb5f6f416e3",
   "metadata": {},
   "source": [
    "## C. Best Tuned Model (using pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63de86e0-0a5f-4a24-a2c7-6cda626d6d84",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 1. Models Hyper Tuned using GridSearchCV: StratifiedKFold(n_splits=10, shuffle=True, random_state=46)\n",
    "\n",
    "- 'Log_Reg':LogisticRegression(C=1.0, max_iter=50, penalty='l2', solver='lbfgs', random_state=46),\n",
    "\n",
    "- 'KN_CLF':KNeighborsClassifier(algorithm='brute', metric='euclidean', n_neighbors=17, weights='distance'),\n",
    "\n",
    "- 'SV_CLF':SVC(C=0.1, degree=2, gamma='auto', kernel='rbf', random_state=46),\n",
    "\n",
    "- 'DT_CLF':DecisionTreeClassifier(criterion='entropy', max_depth=5, min_impurity_decrease=0.0, min_samples_split=0.3, splitter='random', random_state=46),\n",
    "\n",
    "- 'BAG_CLF':BaggingClassifier(bootstrap=True, estimator=DecisionTreeClassifier(), max_samples=0.5, n_estimators=200, oob_score=True, random_state=46),\n",
    "\n",
    "- 'RF_CLF':RandomForestClassifier(bootstrap=True, criterion='entropy', max_depth=5, max_samples=0.5, n_estimators=200, oob_score=True, random_state=46),\n",
    "\n",
    "- 'GB_CLF':GradientBoostingClassifier(learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5, random_state=46),\n",
    "\n",
    "- 'HGB_CLF':HistGradientBoostingClassifier(learning_rate=0.1, max_depth=5, max_iter=200, max_leaf_nodes=25, random_state=46),\n",
    "\n",
    "- 'XGB_CLF':XGBClassifier(eta=0.1, gamma=0.01, max_depth=5, n_estimators=50, subsample=0.5, objective='binary:logistic',\n",
    "                        eval_metric='auc', seed=46)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07a2dbb-fc79-4265-8110-cc6a2e169c78",
   "metadata": {},
   "source": [
    "#### 2. Model's Performance Comparison\n",
    "\n",
    "##### **Model**    ---> ***Acc_Score***\n",
    "\n",
    "##### 1. **GB_CLF**   --->  ***77.2358***\n",
    "##### 2. **XGB_CLF**  --->  ***77.0732***\n",
    "##### 3. **RF_CLF**   --->  ***76.6667***\n",
    "##### 4. **BAG_CLF**  --->  ***76.5854***\n",
    "##### 5. **Log_Reg**  --->  ***76.2602***\n",
    "##### 6. **KN_CLF**   --->  ***76.1789***\n",
    "##### 7. **HGB_CLF**  --->  ***76.0163***\n",
    "##### 8. **SV_CLF**   --->  ***75.3659***\n",
    "##### 9. **DT_CLF**   --->  ***72.3577***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba24f378-918d-4eca-84c2-09eb67ef4cf9",
   "metadata": {},
   "source": [
    "#### 3. Best Model and Parameters\n",
    "\n",
    "- **GradientBoostingClassifier** ***(learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5, random_state=46)***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153fd71c-552f-4971-842c-56f2a23c58cc",
   "metadata": {},
   "source": [
    "#### 4. Best Model Results\n",
    "\n",
    "- StratifiedKFold(n_splits=10, random_state=46, shuffle=True), Cross Validation Score : 77.2358 %, dataset size : (1230,12)\n",
    "- Accuracy Score on Validation Data : 75.0 %, dataset size : (100,12)\n",
    "- ***Accuracy Score on Test Data : 76.0 %***, dataset size : (100,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a847b91-fe0d-4f05-9e31-c290248d0394",
   "metadata": {},
   "source": [
    "## D. Production Model\n",
    "\n",
    "- **GradientBoostingClassifier** ***(learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5, random_state=46)***\n",
    "- StratifiedKFold(n_splits=10, random_state=46, shuffle=True), Cross Validation Score : 76.3831 %, dataset size : (1334,12)\n",
    "- ***Accuracy Score on Test Data : 77.0 %***, dataset size : (100,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0523e131-ecd5-49f0-a0b6-eb596a2703e8",
   "metadata": {},
   "source": [
    "## E. Gradio App Deployment Files\n",
    "- App development is done using 'Production Model' and 'Production Data'.\n",
    "- Production Model saved as 'wine_quality_mdl_prod.pkl' file.\n",
    "- Xtrain set is saved 'wine_quality_X_prod.pkl' file. To access the feature unique values, and ranges.\n",
    "- Test set is saved 'wine_quality_FE_prod_test.pkl' file. To test the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a70ef4-9607-4165-91d4-3997033be93d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
